#!/usr/bin/env python3
"""
Generate docs/qualitative_cases_pre_post.md from the latest lm-eval samples.

Purpose:
- Create a stable index that points to the exact per-sample logs and the generated
  qualitative dumps used for seed comparisons.
- This file is intended to stay up-to-date across reruns (always selects newest files).

Inputs (latest by mtime):
- Baseline samples:
    evals/baseline/baseline_<task>_seed<seed>/*/samples_<task>_*.jsonl
- Post samples (by_adapter view):
    evals/postqlora/by_adapter/<adapter>/<task>_seed<seed>/samples_<task>_*.jsonl

Output:
- docs/qualitative_cases_pre_post.md

Notes / conventions:
- Baseline paths include a sanitized home directory component; we anonymize it for portability.

Determinism / reruns:
- Selected always the newest samples file by mtime to be rerun-safe.
"""

from __future__ import annotations

import argparse
import glob
import os
from pathlib import Path


def newest_matching(pattern: str) -> str:
    # Return newest matching file by mtime to be robust to reruns (multiple samples_*.jsonl).
    matches = glob.glob(pattern)
    if not matches:
        raise FileNotFoundError(f"No files match pattern: {pattern}")
    return max(matches, key=lambda p: os.path.getmtime(p))


def anonymize_model_dir(p: str) -> str:
    # Anonymize lm-eval sanitized home directory component for portability.
    user = os.environ.get("USER", "USER")
    return p.replace(f"__home__{user}__", "__home__USER__")


def main() -> int:
    ap = argparse.ArgumentParser(description="Generate docs/qualitative_cases_pre_post.md from latest samples.")
    ap.add_argument("--seed", type=int, default=0)
    ap.add_argument("--adapters", nargs="*", default=["alpaca_10k", "dolly_full"])
    ap.add_argument("--out", type=Path, default=Path("docs/qualitative_cases_pre_post.md"))
    args = ap.parse_args()

    seed = args.seed
    adapters = args.adapters

    # Resolve project root from the script location so this works from any cwd.
    project_root = Path(__file__).resolve().parents[1]

    # Baseline: lm-eval produces a nested model_dir, so we use a wildcard for that component.
    base_tqa = newest_matching(
        f"evals/baseline/baseline_truthfulqa_mc2_seed{seed}/*/samples_truthfulqa_mc2_*.jsonl"
    )
    base_arc = newest_matching(
        f"evals/baseline/baseline_arc_easy_seed{seed}/*/samples_arc_easy_*.jsonl"
    )

    base_tqa_rel = anonymize_model_dir(Path(base_tqa).resolve().relative_to(project_root).as_posix())
    base_arc_rel = anonymize_model_dir(Path(base_arc).resolve().relative_to(project_root).as_posix())


    # Post: by_adapter provides stable locations per adapter/task/seed.
    post = {}
    for a in adapters:
        post_tqa = newest_matching(
            f"evals/postqlora/by_adapter/{a}/truthfulqa_mc2_seed{seed}/samples_truthfulqa_mc2_*.jsonl"
        )
        post_arc = newest_matching(
            f"evals/postqlora/by_adapter/{a}/arc_easy_seed{seed}/samples_arc_easy_*.jsonl"
        )
        post_tqa_rel = Path(post_tqa).resolve().relative_to(project_root).as_posix()
        post_arc_rel = Path(post_arc).resolve().relative_to(project_root).as_posix()
        post_tqa_rel = anonymize_model_dir(post_tqa_rel)
        post_arc_rel = anonymize_model_dir(post_arc_rel)
        post[a] = (post_tqa_rel, post_arc_rel)




    # Markdown body (links to the detailed dumps).
    lines = []
    lines.append(f"# Qualitative analysis - pre vs post (seed {seed})")
    lines.append("")
    lines.append(
        "This document summarizes the qualitative comparisons extracted from lm-eval-harness per-sample logs (`samples_*.jsonl`)."
    )
    lines.append("")
    lines.append("- Baseline (pre-QLoRA)")
    lines.append("- Post-QLoRA with two representative adapters:")
    for a in adapters:
        lines.append(f"  - `{a}`")
    lines.append("")
    lines.append(f"## Sources (seed {seed})")
    lines.append("")
    lines.append("Baseline (pre-QLoRA):")
    lines.append("")
    # Baseline paths include a sanitized home directory component; anonymize it for portability.
    lines.append(f"- TruthfulQA_mc2 samples: `{base_tqa_rel}`")
    lines.append(f"- ARC-Easy samples: `{base_arc_rel}`")

    lines.append("")
    for a in adapters:
        post_tqa_rel, post_arc_rel = post[a]
        lines.append(f"Post-QLoRA ({a}):")
        lines.append("")
        lines.append(f"- TruthfulQA_mc2 samples: `{post_tqa_rel}`")
        lines.append(f"- ARC-Easy samples: `{post_arc_rel}`")
        lines.append("")

    lines.append("## Post-QLoRA dumps (generated markdown)")
    lines.append("")
    for a in adapters:
        # Dumps generated by scripts/generate_qualitative_cases_post.py.
        lines.append(f"- `{a}` combined: `docs/qualitative_cases_post_{a}_seed{seed}.md`")
        lines.append(f"- `{a}` TruthfulQA only: `docs/qualitative_cases_post_{a}_truthfulqa_seed{seed}.md`")
        lines.append(f"- `{a}` ARC-Easy only: `docs/qualitative_cases_post_{a}_arc_seed{seed}.md`")
        lines.append("")

    lines.append("## Interpretation notes (high level)")
    lines.append("")
    lines.append("- TruthfulQA_mc2: `acc` is a continuous per-item MC2 score (probability mass on true options).")
    lines.append("- ARC-Easy: `acc`/`acc_norm` are effectively binary per-item; inspect improvements/degradations in the dumps.")
    lines.append("")

    args.out.parent.mkdir(parents=True, exist_ok=True)
    args.out.write_text("\n".join(lines), encoding="utf-8")
    print(f"[generate_qualitative_cases_pre_post] Wrote: {args.out}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
